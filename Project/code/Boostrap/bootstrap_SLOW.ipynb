{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d629ac59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: torch.Size([307, 8]) torch.Size([307, 1])\n",
      "Cal  : torch.Size([307, 8]) torch.Size([307, 1])\n",
      "Test : torch.Size([154, 8]) torch.Size([154, 1])\n",
      "=== Split Conformal ===\n",
      "{'coverage': 0.8896103896103896, 'avg_len': 3.0321617, 'train_time': 0.6756629943847656, 'cal_time': 0.0008099079132080078, 'test_time': 8.320808410644531e-05, 'total_time': 0.6765561103820801, 'q_hat': 0.15206149816513073}\n",
      "\n",
      "=== Bootstrap, B=5 ===\n",
      "{'coverage': 0.44805194805194803, 'avg_len': 2.092079302336545, 'train_time': 3.001145839691162, 'pred_time': 0.00034427642822265625, 'total_time': 3.0014901161193848}\n",
      "\n",
      "=== Bootstrap, B=10 ===\n",
      "{'coverage': 0.6038961038961039, 'avg_len': 2.371622004570438, 'train_time': 6.057910203933716, 'pred_time': 0.00043392181396484375, 'total_time': 6.058344125747681}\n",
      "\n",
      "=== Bootstrap, B=20 ===\n",
      "{'coverage': 0.6038961038961039, 'avg_len': 2.7865296517702665, 'train_time': 12.030375957489014, 'pred_time': 0.0005068778991699219, 'total_time': 12.030882835388184}\n",
      "\n",
      "=== Bootstrap, B=100 ===\n",
      "{'coverage': 0.6883116883116883, 'avg_len': 3.0967806825269157, 'train_time': 61.36106777191162, 'pred_time': 0.0012841224670410156, 'total_time': 61.36235189437866}\n",
      "\n",
      "=== Bootstrap, B=300 ===\n",
      "{'coverage': 0.7467532467532467, 'avg_len': 3.226970005940535, 'train_time': 181.73309302330017, 'pred_time': 0.0028960704803466797, 'total_time': 181.73598909378052}\n",
      "\n",
      "=== Bootstrap, B=600 ===\n",
      "{'coverage': 0.7532467532467533, 'avg_len': 3.227711706693992, 'train_time': 359.53008818626404, 'pred_time': 0.005324840545654297, 'total_time': 359.5354130268097}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# =========================\n",
    "# 1. 读数据 + 划分 + 标准化\n",
    "# =========================\n",
    "df = pd.read_excel(\"../../data/ENB2012_data.xlsx\")\n",
    "X = df.iloc[:, :8].values.astype(np.float32)\n",
    "y = df.iloc[:, 8].values.astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0\n",
    ")\n",
    "\n",
    "scaler_x = StandardScaler().fit(X_train_full)\n",
    "scaler_y = StandardScaler().fit(y_train_full)\n",
    "\n",
    "X_train_full = scaler_x.transform(X_train_full)\n",
    "X_test       = scaler_x.transform(X_test)\n",
    "y_train_full = scaler_y.transform(y_train_full)\n",
    "y_test       = scaler_y.transform(y_test)\n",
    "\n",
    "# 再把训练集一分为二：train / cal，给 split CP 用\n",
    "X_tr, X_cal, y_tr, y_cal = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.5, random_state=1\n",
    ")\n",
    "\n",
    "X_tr  = torch.tensor(X_tr,  dtype=torch.float32).to(device)\n",
    "y_tr  = torch.tensor(y_tr,  dtype=torch.float32).to(device)\n",
    "X_cal = torch.tensor(X_cal, dtype=torch.float32).to(device)\n",
    "y_cal = torch.tensor(y_cal, dtype=torch.float32).to(device)\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "print(\"Train:\", X_tr.shape, y_tr.shape)\n",
    "print(\"Cal  :\", X_cal.shape, y_cal.shape)\n",
    "print(\"Test :\", X_test_t.shape, y_test_t.shape)\n",
    "\n",
    "# =========================\n",
    "# 2. 定义一个简单 MLP\n",
    "# =========================\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim=8, hidden=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, 1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def train_mlp(X, y, epochs=200, batch_size=64, lr=1e-3):\n",
    "    ds = TensorDataset(X, y)\n",
    "    dl = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "    model = MLP(in_dim=X.shape[1]).to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        for xb, yb in dl:\n",
    "            opt.zero_grad()\n",
    "            pred = model(xb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "    return model\n",
    "\n",
    "# =========================\n",
    "# 3. Split Conformal (一次训练)\n",
    "# =========================\n",
    "def split_conformal(alpha=0.1):\n",
    "    t0 = time.time()\n",
    "    model = train_mlp(X_tr, y_tr)\n",
    "    t1 = time.time()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        mu_cal = model(X_cal)\n",
    "    resid = (y_cal - mu_cal).abs().cpu().numpy().ravel()\n",
    "    q_hat = np.quantile(resid, 1 - alpha)\n",
    "    t2 = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        mu_test = model(X_test_t)\n",
    "    mu_test_np = mu_test.cpu().numpy().ravel()\n",
    "    lower = mu_test_np - q_hat\n",
    "    upper = mu_test_np + q_hat\n",
    "    t3 = time.time()\n",
    "\n",
    "    # 还原回原尺度，方便算 coverage / 长度\n",
    "    y_test_np = scaler_y.inverse_transform(y_test).ravel()\n",
    "    mu_test_raw = scaler_y.inverse_transform(mu_test_np.reshape(-1, 1)).ravel()\n",
    "    lower_raw   = scaler_y.inverse_transform(lower.reshape(-1, 1)).ravel()\n",
    "    upper_raw   = scaler_y.inverse_transform(upper.reshape(-1, 1)).ravel()\n",
    "\n",
    "    coverage = np.mean((y_test_np >= lower_raw) & (y_test_np <= upper_raw))\n",
    "    avg_len  = np.mean(upper_raw - lower_raw)\n",
    "\n",
    "    train_time = t1 - t0\n",
    "    cal_time   = t2 - t1\n",
    "    test_time  = t3 - t2\n",
    "    total_time = t3 - t0\n",
    "\n",
    "    return dict(\n",
    "        coverage=coverage,\n",
    "        avg_len=avg_len,\n",
    "        train_time=train_time,\n",
    "        cal_time=cal_time,\n",
    "        test_time=test_time,\n",
    "        total_time=total_time,\n",
    "        q_hat=q_hat,\n",
    "    )\n",
    "\n",
    "# =========================\n",
    "# 4. Bootstrap 预测区间 (训练 B 次 + 预测 B 次)\n",
    "# =========================\n",
    "def bootstrap_pi(B=20, alpha=0.1, epochs=200):\n",
    "    n_tr = X_tr.shape[0]\n",
    "    t0 = time.time()\n",
    "    preds = []\n",
    "\n",
    "    for b in range(B):\n",
    "        idx = np.random.choice(n_tr, n_tr, replace=True)\n",
    "        X_b = X_tr[idx]\n",
    "        y_b = y_tr[idx]\n",
    "        model_b = train_mlp(X_b, y_b, epochs=epochs)\n",
    "        model_b.eval()\n",
    "        with torch.no_grad():\n",
    "            mu_test_b = model_b(X_test_t)\n",
    "        preds.append(mu_test_b.cpu().numpy().ravel())\n",
    "\n",
    "    t1 = time.time()\n",
    "    preds = np.stack(preds, axis=0)  # (B, n_test)\n",
    "\n",
    "    lower = np.quantile(preds, alpha/2, axis=0)\n",
    "    upper = np.quantile(preds, 1 - alpha/2, axis=0)\n",
    "    t2 = time.time()\n",
    "\n",
    "    # 还原尺度\n",
    "    y_test_np = scaler_y.inverse_transform(y_test).ravel()\n",
    "    lower_raw = scaler_y.inverse_transform(lower.reshape(-1, 1)).ravel()\n",
    "    upper_raw = scaler_y.inverse_transform(upper.reshape(-1, 1)).ravel()\n",
    "\n",
    "    coverage = np.mean((y_test_np >= lower_raw) & (y_test_np <= upper_raw))\n",
    "    avg_len  = np.mean(upper_raw - lower_raw)\n",
    "\n",
    "    train_time = t1 - t0      # 训练 B 个网络的时间\n",
    "    pred_time  = t2 - t1      # 在测试集上聚合分位数的时间\n",
    "    total_time = t2 - t0\n",
    "\n",
    "    return dict(\n",
    "        coverage=coverage,\n",
    "        avg_len=avg_len,\n",
    "        train_time=train_time,\n",
    "        pred_time=pred_time,\n",
    "        total_time=total_time,\n",
    "    )\n",
    "\n",
    "# =========================\n",
    "# 5. 跑一遍对比\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    alpha = 0.1\n",
    "\n",
    "    print(\"=== Split Conformal ===\")\n",
    "    res_sc = split_conformal(alpha=alpha)\n",
    "    print(res_sc)\n",
    "    Bs = [5, 10, 20,100,300,600]\n",
    "    for B in [5, 10, 20,100,300,600]:\n",
    "        print(f\"\\n=== Bootstrap, B={B} ===\")\n",
    "        res_boot = bootstrap_pi(B=B, alpha=alpha, epochs=200)\n",
    "        print(res_boot)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
