{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf42542c",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "## (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaa454b",
   "metadata": {},
   "source": [
    "We use EM algorithm to estimate $\\pi$ and $\\sigma^2$, and calculate $\\hat \\mu_i^S$ by the algorithm's output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befecbe3",
   "metadata": {},
   "source": [
    "From the hierarchical model，we can derive\n",
    "$$\n",
    "z_i \\mid {\\gamma_i = 0} \\sim \\mathcal{N}(0, 1), \\\\\n",
    "z_i \\mid {\\gamma_i = 1 }\\sim \\mathcal{N}(0, 1 + \\sigma^2),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85babf76",
   "metadata": {},
   "source": [
    "For each i\n",
    "$$\n",
    "p(z_i,\\gamma_i|\\pi,\\sigma^2) = p(\\gamma_i|\\pi)p(z_i|\\gamma_i,\\sigma^2)\n",
    "$$\n",
    "\n",
    "By the defination\n",
    "\n",
    "$$\n",
    "p(\\gamma_i|\\pi) = \\pi^{\\gamma_i}(1-\\pi)^{1-\\gamma_i}\n",
    "\\\\\n",
    "p(z_i|\\gamma_i,\\sigma^2)=[\\phi(z_i;0,1+\\sigma^2)]^{\\gamma_i}[\\phi(z_i;0,1)]^{(1-\\gamma_i)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdaaa0f",
   "metadata": {},
   "source": [
    "where \n",
    "$\n",
    "\\phi(z;a,b) = (2\\pi b)^{-1/2} \\exp\\!\\left(-\\frac{(z-a)^2}{2b}\\right).\n",
    "$ is the probabilty density funtion of normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eb4a2d",
   "metadata": {},
   "source": [
    "Thus we can deduce\n",
    "$$\n",
    "p(z_i,\\gamma_i|\\pi,\\sigma^2)=[\\pi\\phi(z_i;0,1+\\sigma^2)]^{\\gamma_i}[\\pi\\phi(z_i;0,1)]^{(1-\\gamma_i)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28493506",
   "metadata": {},
   "source": [
    "And then the complete-data log-likelihood is\n",
    "\n",
    "$$\n",
    "\\ell_c(\\pi,\\sigma^2)\n",
    "=\\sum_{i=1}^N\n",
    "\\Big[\n",
    "\\gamma_i\\big(\\log\\pi+\\log\\phi(z_i;0,1+\\sigma^2)\\big)\n",
    "+(1-\\gamma_i)\\big(\\log(1-\\pi)+\\log\\phi(z_i;0,1)\\big)\n",
    "\\Big],\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "which equal to \n",
    "\n",
    "$$\n",
    "\\ell_c(\\pi,\\sigma^2)\n",
    "=\\sum_{i=1}^N\n",
    "\\Big[\n",
    "\\gamma_i\\Big(\\log\\pi - \\frac{1}{2}\\log(1+\\sigma^2) - \\frac{z_i^2}{2(1+\\sigma^2)}\\Big)\n",
    "+(1-\\gamma_i)\\log(1-\\pi)\n",
    "\\Big] + C\n",
    "$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e657c40f",
   "metadata": {},
   "source": [
    "$C$ includes all terms that are unrelated to $\\pi$ and $\\sigma^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812ee7a4",
   "metadata": {},
   "source": [
    "### E step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8c553e",
   "metadata": {},
   "source": [
    "Define the responsibility\n",
    "$$\n",
    "w_i^{(t)} = \\mathbb E[\\gamma_i \\mid z_i;\\pi^{(t)},\\sigma^{2(t)}]\n",
    "= P(\\gamma_i=1\\mid z_i;\\pi^{(t)},\\sigma^{2(t)}).\n",
    "= \\frac{\\pi^{(t)}p(z_i|\\gamma_i=1,\\sigma^{2(t)})}{\\pi^{(t)}p(z_i|\\gamma_i=1,\\sigma^{2(t)})+(1-\\pi^{(t)})p(z_i|\\gamma_i=0)}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8af081",
   "metadata": {},
   "source": [
    "Thus \n",
    "$$\n",
    "Q(\\pi,\\sigma^2|\\pi^{(t)},\\sigma^{2(t)}) = \\sum_{i=1}^N [w_i^{(t)}(\\log\\pi - \\frac{1}{2}\\log(1+\\sigma^2) - \\frac{z_i^2}{2(1+\\sigma^2)} )+(1-w_i^{(t)})\\log(1-\\pi)] +C\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797b37cf",
   "metadata": {},
   "source": [
    "### M step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518943ef",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "\\frac{\\partial Q}{\\partial \\pi}\n",
    "=\\sum_{i=1}^N\\Big(\\frac{w_i^{(t)}}{\\pi}-\\frac{1-w_i^{(t)}}{1-\\pi}\\Big)=0\n",
    "\\quad\\Rightarrow\\quad\n",
    "\\pi^{(t+1)}=\\frac{1}{N}\\sum_{i=1}^N w_i^{(t)}.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fedc9e7",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "\\frac{\\partial Q}{\\partial \\sigma^2}\n",
    "=\\sum_{i=1}^N w_i^{(t)}\\Big(-\\frac{1}{2(1+\\sigma^2)}+\\frac{z_i^2}{2(1+\\sigma^2)^2}\\Big)=0.\n",
    "\\quad\\Rightarrow\\quad\n",
    "\\sigma^{2(t+1)}=\\frac{\\sum_{i=1}^N w_i^{(t)} z_i^2}{\\sum_{i=1}^N w_i^{(t)}}-1. (\\ge 0)\n",
    "\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9d41c8",
   "metadata": {},
   "source": [
    "Repeat E step and M step until the parameters converge, yielding $\\hat \\pi$ and $\\hat \\sigma^2$, using these estimates, compute the posterior mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bd65d3",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{w}_{i}=\\frac{\\hat{\\pi}\\mathrm{~}\\phi{\\left(z_{i};0,\\mathrm{~}1+\\hat{\\sigma}^{2}\\right)}}{\\hat{\\pi}\\mathrm{~}\\phi{\\left(z_{i};0,\\mathrm{~}1+\\hat{\\sigma}^{2}\\right)}+(1-\\hat{\\pi})\\phi{\\left(z_{i};0,\\mathrm{~}1\\right)}}\n",
    "\\\\\n",
    "\\hat{\\mu}_{i}^{S}=\\hat{w}_{i}\\frac{\\hat{\\sigma}^{2}}{1+\\hat{\\sigma}^{2}}z_{i}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126123bc",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0655dc5a",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf80ef5e",
   "metadata": {},
   "source": [
    "For Tweedie’s formula, we estimate the marginal density $f(z)$ using KDE with the Gaussian kernel $\\phi(u)=\\frac{1}{\\sqrt{2\\pi}}e^{-u^{2}/2}$:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e035b3",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{f}(z)=\\frac{1}{Nh}\\sum_{j=1}^N\\phi{\\left(\\frac{z-z_j}{h}\\right)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3926a9",
   "metadata": {},
   "source": [
    "The bandwidth $h$ is selected using Silverman’s rule:\n",
    "$h = 1.06\\,\\hat{s}\\,N^{-1/5}$, where $\\hat{s}$ is the sample standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100d22ed",
   "metadata": {},
   "source": [
    "Thus the score function is \n",
    "\n",
    "$$\n",
    "\\frac{d}{dz}\\log\\hat{f}(z)=\\frac{\\sum_{j=1}^N\\frac{z-z_j}{h^2}\\phi{\\left(\\frac{z-z_j}{h}\\right)}}{\\sum_{j=1}^N\\phi{\\left(\\frac{z-z_j}{h}\\right)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93697ed2",
   "metadata": {},
   "source": [
    "thus the Tweedie estimator is\n",
    "\n",
    "$$\n",
    "\\hat{\\mu}_i^{\\mathrm{Tw}}=z_i+\\frac{d}{dz}\\log\\hat{f}(z_i) = z_i +\\frac{\\sum_{j=1}^N\\frac{z_i-z_j}{h^2}\\phi{\\left(\\frac{z_i-z_j}{h}\\right)}}{\\sum_{j=1}^N\\phi{\\left(\\frac{z_i-z_j}{h}\\right)}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8b8f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Tweedie's formular \n",
    "# KDE to estimate the density function\n",
    "##\n",
    "import numpy as np\n",
    "def tweedie(z, tau2=1.0, eps=1e-12):\n",
    "    z = np.asarray(z, dtype=float).ravel()\n",
    "    N = z.size\n",
    "\n",
    "    if N == 0:\n",
    "        return np.array([]), np.nan\n",
    "    if N == 1:\n",
    "        return z.copy(), 1.0\n",
    "\n",
    "    # --- Silverman's rule of thumb (classic) ---\n",
    "    s = np.std(z, ddof=1)  # unbiased std\n",
    "    if s == 0:\n",
    "        s = 1.0  # fallback if all z are identical\n",
    "    h = 1.06 * s * (N ** (-1.0 / 5.0))\n",
    "\n",
    "    # Precompute constants\n",
    "    inv_h = 1.0 / h\n",
    "    inv_h2 = inv_h * inv_h\n",
    "\n",
    "    # Pairwise differences: shape (N, N)\n",
    "    diff = z[:, None] - z[None, :]          # z_i - z_j\n",
    "    u = diff * inv_h                        # (z_i - z_j) / h\n",
    "\n",
    "    # Gaussian kernel (constant factor cancels, so omit 1/sqrt(2π))\n",
    "    K = np.exp(-0.5 * u * u)                # proportional to φ(u)\n",
    "\n",
    "    # Denominator: sum_j K_ij\n",
    "    den = np.sum(K, axis=1)\n",
    "\n",
    "    # Numerator: sum_j (z_i - z_j)/h^2 * K_ij\n",
    "    num = np.sum(diff * K, axis=1) * inv_h2\n",
    "\n",
    "    # Score = d/dz log f_hat(z_i)\n",
    "    score = num / np.maximum(den, eps)\n",
    "\n",
    "    # Tweedie estimate\n",
    "    mu_hat = z + tau2 * score\n",
    "\n",
    "    return mu_hat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e721f509",
   "metadata": {},
   "source": [
    "JSE:  \n",
    "$$\n",
    "\\hat{\\boldsymbol{\\mu}}^{\\mathrm{~JS}}=\\left(1-\\frac{d-2}{\\|\\mathbf{z}\\|^{2}}\\right)_{+}\\mathbf{z},\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8f930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def JSE(z, sigma2=1.0, center=None, positive_part=True):\n",
    "\n",
    "    z = np.asarray(z, dtype=float)\n",
    "    original_shape = z.shape\n",
    "\n",
    "    if z.ndim == 1:\n",
    "        z = z[None, :]  # shape (1, d)\n",
    "        squeeze_output = True\n",
    "    else:\n",
    "        squeeze_output = False\n",
    "\n",
    "    N, d = z.shape\n",
    "\n",
    "    if d < 3:\n",
    "        raise ValueError(\"James-Stein estimator is only defined for dimension d >= 3\")\n",
    "        pass\n",
    "\n",
    "    # Set center\n",
    "    if center is None:\n",
    "        center = np.zeros(d)\n",
    "    else:\n",
    "        center = np.asarray(center, dtype=float)\n",
    "        if center.shape != (d,):\n",
    "            raise ValueError(f\"center must be shape ({d},), got {center.shape}\")\n",
    "\n",
    "    # Center the data\n",
    "    z_centered = z - center  # shape (N, d)\n",
    "\n",
    "    # Squared norm: ||z - center||^2, shape (N,)\n",
    "    norm_sq = np.sum(z_centered**2, axis=1)\n",
    "\n",
    "    # Avoid division by zero\n",
    "    eps = np.finfo(float).eps\n",
    "    norm_sq = np.maximum(norm_sq, eps)\n",
    "\n",
    "    # Shrinkage factor: (d - 2) * sigma2 / ||z - center||^2\n",
    "    shrinkage = (d - 2) * sigma2 / norm_sq  # shape (N,)\n",
    "\n",
    "    if positive_part:\n",
    "        factor = np.maximum(1.0 - shrinkage, 0.0)\n",
    "    else:\n",
    "        factor = 1.0 - shrinkage\n",
    "\n",
    "    # Apply shrinkage\n",
    "    mu_hat = center + (factor[:, None] * z_centered)\n",
    "\n",
    "    # Reshape to match input\n",
    "    if squeeze_output:\n",
    "        mu_hat = mu_hat[0]\n",
    "\n",
    "    return mu_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b268b1",
   "metadata": {},
   "source": [
    "EM：Provided in （a）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da44010e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi_hat=0.0773, sigma2_hat=2.6184, iterations=73\n",
      "MSE(EM posterior mean) = 0.1652\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def em_spike_slab(z, pi_init=0.2, sigma2_init=1.0, tol=1e-6, max_iter=1000,\n",
    "                  min_sigma2=1e-8, return_history=False):\n",
    "\n",
    "    z = np.asarray(z, dtype=float).ravel()\n",
    "    N = z.size\n",
    "\n",
    "    # --- helpers ---\n",
    "    def log_norm_pdf(x, mean, var):\n",
    "        return -0.5 * (np.log(2.0 * np.pi * var) + (x - mean) ** 2 / var)\n",
    "\n",
    "    def obs_loglik(pi, sigma2):\n",
    "        # log [ pi * N(0,1+sigma2) + (1-pi) * N(0,1) ] summed over i\n",
    "        la = np.log(pi)   + log_norm_pdf(z, 0.0, 1.0 + sigma2)\n",
    "        lb = np.log(1-pi) + log_norm_pdf(z, 0.0, 1.0)\n",
    "        m = np.maximum(la, lb)\n",
    "        return np.sum(m + np.log(np.exp(la - m) + np.exp(lb - m)))\n",
    "\n",
    "    # --- init ---\n",
    "    pi = float(np.clip(pi_init, 1e-6, 1-1e-6))\n",
    "    sigma2 = float(max(sigma2_init, min_sigma2))\n",
    "    last_ll = -np.inf\n",
    "\n",
    "    if return_history:\n",
    "        hist_pi, hist_s2, hist_ll = [], [], []\n",
    "\n",
    "    for t in range(1, max_iter + 1):\n",
    "        # E-step: responsibilities w_i = P(gamma=1 | z_i, pi, sigma2)\n",
    "        la = np.log(pi)   + log_norm_pdf(z, 0.0, 1.0 + sigma2)\n",
    "        lb = np.log(1-pi) + log_norm_pdf(z, 0.0, 1.0)\n",
    "        m  = np.maximum(la, lb)\n",
    "        a  = np.exp(la - m)\n",
    "        b  = np.exp(lb - m)\n",
    "        w  = a / (a + b)                 # shape (N,)\n",
    "\n",
    "        # M-step:\n",
    "        pi_new = np.clip(np.mean(w), 1e-12, 1 - 1e-12)\n",
    "        denom = np.sum(w)\n",
    "        if denom < 1e-16:\n",
    "            sigma2_new = min_sigma2      # degenerate case: all weights ~ 0\n",
    "        else:\n",
    "            sigma2_new = np.sum(w * z**2) / denom - 1.0\n",
    "            sigma2_new = float(max(sigma2_new, min_sigma2))\n",
    "\n",
    "        # Check convergence via observed-data log-likelihood\n",
    "        ll = obs_loglik(pi_new, sigma2_new)\n",
    "\n",
    "        if return_history:\n",
    "            hist_pi.append(pi_new)\n",
    "            hist_s2.append(sigma2_new)\n",
    "            hist_ll.append(ll)\n",
    "\n",
    "        if np.isfinite(last_ll) and abs(ll - last_ll) <= tol * (1.0 + abs(last_ll)):\n",
    "            pi, sigma2 = pi_new, sigma2_new\n",
    "            break\n",
    "\n",
    "        pi, sigma2 = pi_new, sigma2_new\n",
    "        last_ll = ll\n",
    "\n",
    "    # Posterior mean with the learned params\n",
    "    la = np.log(pi)   + log_norm_pdf(z, 0.0, 1.0 + sigma2)\n",
    "    lb = np.log(1-pi) + log_norm_pdf(z, 0.0, 1.0)\n",
    "    m  = np.maximum(la, lb)\n",
    "    a  = np.exp(la - m)\n",
    "    b  = np.exp(lb - m)\n",
    "    w  = a / (a + b)\n",
    "\n",
    "    shrink = sigma2 / (1.0 + sigma2)\n",
    "    mu_hat = w * shrink * z\n",
    "\n",
    "    if return_history:\n",
    "        return pi, sigma2, mu_hat, {\n",
    "            \"pi\": np.array(hist_pi),\n",
    "            \"sigma2\": np.array(hist_s2),\n",
    "            \"loglik\": np.array(hist_ll),\n",
    "            \"iters\": t,\n",
    "        }\n",
    "    return pi, sigma2, mu_hat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1f320d",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9754fbc1",
   "metadata": {},
   "source": [
    "Generate data for the normal means model with a spike–slab prior:\n",
    "\n",
    "$$\n",
    "gamma_i ~ Bernoulli(pi)\n",
    "mu_i | gamma_i = 1 ~ N(0, sigma2),  mu_i | gamma_i = 0 = 0\n",
    "z_i = mu_i + eps_i,  eps_i ~ N(0, tau2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc5b7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonzeros = 16 / 200, z mean = -0.028\n"
     ]
    }
   ],
   "source": [
    "def generate_data(\n",
    "    N: int,\n",
    "    pi: float,\n",
    "    sigma2: float = 1.0,\n",
    "    tau2: float = 1.0,\n",
    "    rng: np.random.Generator | None = None,\n",
    "):\n",
    "\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    if not (0.0 < pi < 1.0):\n",
    "        raise ValueError(\"pi must be in (0,1).\")\n",
    "    if sigma2 < 0 or tau2 < 0:\n",
    "        raise ValueError(\"sigma2 and tau2 must be nonnegative.\")\n",
    "\n",
    "    gamma = rng.binomial(1, pi, size=N).astype(int)\n",
    "    mu = rng.normal(0.0, np.sqrt(sigma2), size=N) * gamma\n",
    "    z = mu + rng.normal(0.0, np.sqrt(tau2), size=N)\n",
    "    return mu, z, gamma\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971a1af9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
